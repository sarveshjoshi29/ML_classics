{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1764022",
   "metadata": {},
   "source": [
    "Creator - Sarvesh Joshi \n",
    "\n",
    "Date of creation - 14/7/2025\n",
    "\n",
    "Last updated - 15/7/2025\n",
    "\n",
    "UPDATE 1 - cleared rounds,leaves,node before fitting and building tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60fc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34a513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self,feature = None ,split_value = None,depth = 0,data=None,Gradients = None, Hessians = None):\n",
    "        self.feature = feature\n",
    "        self.split_value = split_value\n",
    "        self.depth = depth\n",
    "        self.data = data\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.Gradients = Gradients\n",
    "        self.Hessians = Hessians \n",
    "        self.is_leaf = True if feature ==-1 else False \n",
    "\n",
    "    def out(self,lambd,alpha):\n",
    "        if self.is_leaf == True:\n",
    "            G = np.sum(self.Gradients)\n",
    "            H = np.sum(self.Hessians)\n",
    "    \n",
    "            if G > alpha:\n",
    "                return -(G-alpha)/(H+lambd)\n",
    "            elif G < -alpha:\n",
    "                return -(G+alpha)/(H+lambd)\n",
    "            else:\n",
    "                return 0\n",
    "    \n",
    "\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self,root):\n",
    "        self.root = root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostBinaryClassifier():\n",
    "    def __init__(self,max_depth = 10,loss = \"logloss\",min_split_loss= 0,learning_rate = 1,l2_regularization = 0,max_iter = 1,l1_regularization = 0,min_child_weight=0,subsample = 1):\n",
    "        self.max_depth = max_depth\n",
    "        self.loss = loss.lower()\n",
    "        self.gamma = min_split_loss\n",
    "        self.lambd = l2_regularization\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = l1_regularization\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.subsample = subsample\n",
    "        self.rounds = []\n",
    "\n",
    "    \n",
    "    \n",
    "    class Round():\n",
    "        def __init__(self,xgboost_instance,round_num):\n",
    "            self.xgboost = xgboost_instance\n",
    "            self.round_num = round_num \n",
    "            self.tree = None\n",
    "            self.Gradients = None\n",
    "            self.Hessians = None\n",
    "            self.leaves = []\n",
    "            self.nodes = []\n",
    "\n",
    "        def compute_gradients(self,y_train,y_guess):\n",
    "            if self.xgboost.loss == \"logloss\":\n",
    "                y_prob = 1/(1+np.exp(-y_guess))\n",
    "                G = y_prob-y_train\n",
    "                H = (y_prob)*(1-y_prob)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"loss function can only be logloss\")\n",
    "            \n",
    "            self.Gradients = G\n",
    "            self.Hessians = H\n",
    "            #print(self.Hessians)\n",
    "\n",
    "        def find_split_value(self,X,Gradients,Hessians):\n",
    "            feature =-1\n",
    "                # if feature isnt found it stays at -1 and node becomes a leaf\n",
    "            split_value = 0\n",
    "            gamma = self.xgboost.gamma\n",
    "            lambd = self.xgboost.lambd\n",
    "            min_child_weight = self.xgboost.min_child_weight\n",
    "            G = np.sum(Gradients)\n",
    "            H = np.sum(Hessians)\n",
    "            parent_score = 0.5*((G**2)/(H+lambd))\n",
    "            max_gain = -np.inf\n",
    "            \n",
    "\n",
    "            for curr_feature in range(X.shape[1]):  \n",
    "                sort_mask = X[:,curr_feature].argsort()\n",
    "                X_sorted = X[sort_mask]\n",
    "                G_sorted = Gradients[sort_mask]\n",
    "                H_sorted = Hessians[sort_mask]\n",
    "                G_L= 0\n",
    "                H_L = 0\n",
    "                for i in range(len(X_sorted)-1):\n",
    "                    curr_split_value = (X_sorted[i, curr_feature] + X_sorted[i+1, curr_feature]) / 2\n",
    "                    G_L += G_sorted[i]\n",
    "                    H_L += H_sorted[i]\n",
    "                    G_R = G - G_L\n",
    "                    H_R = H - H_L\n",
    "\n",
    "                    # if equal values come then split point will be wrongly detected\n",
    "                    if X_sorted[i,curr_feature] == X_sorted[i+1,curr_feature]:\n",
    "                        continue\n",
    "                    \n",
    "                    curr_gain  = 0.5*((G_L**2)/(H_L + lambd + 1e-12) + (G_R**2)/(H_R+lambd+1e-12)- parent_score) - gamma\n",
    "                    if (curr_gain >= 0) and (curr_gain > max_gain) :\n",
    "                        if (H_L >= min_child_weight) and (H_R>=min_child_weight):\n",
    "                            feature = curr_feature\n",
    "                            split_value = curr_split_value\n",
    "                            max_gain = curr_gain\n",
    "            \n",
    "            return feature,split_value\n",
    "        \n",
    "        def create_node(self,data,depth,Gradients,Hessians):\n",
    "            feature,split_value = self.find_split_value(data,Gradients=Gradients,Hessians=Hessians)\n",
    "\n",
    "            \n",
    "            new_node = Node(feature=feature,split_value=split_value,depth=depth,data=data,Gradients=Gradients,Hessians=Hessians)\n",
    "            self.nodes.append(new_node)\n",
    "            return new_node        \n",
    "        \n",
    "\n",
    "        def build_tree(self,X):\n",
    "            \n",
    "            self.nodes.clear()\n",
    "            self.leaves.clear()\n",
    "            curr_depth = 1\n",
    "            root = self.create_node(data = X,depth=curr_depth,Gradients=self.Gradients,Hessians=self.Hessians)\n",
    "            #print(root.is_leaf)\n",
    "            queue = [root]\n",
    "            leaves = []\n",
    "            while((curr_depth+1<=self.xgboost.max_depth) and (len(queue)!=0)):\n",
    "                curr_node = queue.pop(0)\n",
    "                curr_depth = curr_node.depth\n",
    "                curr_data = curr_node.data\n",
    "                curr_Grads = curr_node.Gradients\n",
    "                curr_Hess = curr_node.Hessians\n",
    "\n",
    "                if curr_depth+1 == self.xgboost.max_depth:\n",
    "                    curr_node.is_leaf = True\n",
    "                    leaves.append(curr_node)\n",
    "\n",
    "                if not curr_node.is_leaf:\n",
    "                    mask_left = curr_data[:,curr_node.feature] < curr_node.split_value\n",
    "                    mask_right = curr_data[:,curr_node.feature] >= curr_node.split_value\n",
    "\n",
    "\n",
    "                    # Empty masks is creating NaN values ahead !\n",
    "                    if (np.sum(mask_left)>0 and np.sum(mask_right) > 0) :\n",
    "\n",
    "                        curr_node.left = self.create_node(depth=curr_depth+1,data = curr_data[mask_left],Gradients= curr_Grads[mask_left],Hessians=curr_Hess[mask_left])\n",
    "                        curr_node.right = self.create_node(depth=curr_depth+1,data = curr_data[mask_right],Gradients= curr_Grads[mask_right],Hessians=curr_Hess[mask_right])\n",
    "                        queue.append(curr_node.left)\n",
    "                        queue.append(curr_node.right)\n",
    "\n",
    "                    else:\n",
    "                        curr_node.is_leaf = True\n",
    "                        leaves.append(curr_node)\n",
    "                \n",
    "                elif curr_node.is_leaf:\n",
    "                    leaves.append(curr_node)\n",
    "            \n",
    "            \n",
    "            self.tree = Tree(root=root)\n",
    "            self.leaves = leaves\n",
    "\n",
    "\n",
    "            # for node in self.nodes:\n",
    "            #     if (node.is_leaf == False) and (node.left == None) and(node.right==None):\n",
    "            #         print(len(node.data))\n",
    "        \n",
    "        def evaluate_tree(self,X,y_guess):\n",
    "            if self.tree is None or self.tree.root is None:\n",
    "                raise ValueError(\"Tree not built yet. Please call fit before predict\")\n",
    "            #print(self.tree.root.left)\n",
    "            f = []\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                curr_node = self.tree.root\n",
    "\n",
    "                \n",
    "                while curr_node.is_leaf == False:\n",
    "                    curr_feature = curr_node.feature\n",
    "                    curr_split_value = curr_node.split_value\n",
    "\n",
    "                    if X[i,curr_feature] < curr_split_value:\n",
    "                        curr_node = curr_node.left\n",
    "                        \n",
    "                    else :\n",
    "                        curr_node = curr_node.right\n",
    "                    #print(curr_node.is_leaf)\n",
    "                        \n",
    "                f.append(curr_node.out(lambd= self.xgboost.lambd,alpha = self.xgboost.alpha))\n",
    "                #print(curr_node.out(lambd= self.xgboost.lambd,alpha = self.xgboost.alpha))\n",
    "            f = np.array(f,dtype=float)\n",
    "            f = f.reshape(y_guess.shape)\n",
    "            #print(type(f))\n",
    "            y_guess_new = y_guess + self.xgboost.learning_rate*f\n",
    "            return y_guess_new\n",
    "    \n",
    "\n",
    "    def create_round(self,round_num):\n",
    "        round = self.Round(xgboost_instance=self,round_num=round_num)\n",
    "        return round\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        if isinstance(X_train,pd.DataFrame):\n",
    "            X_train = X_train.values\n",
    "        if (isinstance(y_train,pd.DataFrame)) or (isinstance(y_train,pd.Series)):\n",
    "            y_train = y_train.values\n",
    "        y_train = y_train.ravel()\n",
    "        self.rounds.clear()\n",
    "        for i in range(self.max_iter):\n",
    "            round_num = i+1\n",
    "            self.rounds.append(self.create_round(round_num))\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_guess = np.zeros(y_train.shape,dtype = float)\n",
    "        \n",
    "        \n",
    "        for round in self.rounds:\n",
    "            subsample = self.subsample\n",
    "            num_select = int(len(X_train)*subsample)\n",
    "            mask = np.random.choice(len(X_train),size=num_select,replace=False)\n",
    "            X_train_sub = X_train[mask]\n",
    "            y_train_sub = y_train[mask]\n",
    "            y_guess_sub = y_guess[mask]\n",
    "            round.compute_gradients(y_train_sub,y_guess_sub)\n",
    "            round.build_tree(X_train_sub)\n",
    "            y_guess = round.evaluate_tree(X_train,y_guess)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        if isinstance(X_test,pd.DataFrame):\n",
    "            X_test = X_test.values\n",
    "        y_guess = np.zeros(X_test.shape[0])\n",
    "\n",
    "\n",
    "        for round in self.rounds:\n",
    "            y_guess = round.evaluate_tree(X_test,y_guess)\n",
    "        probs = 1/(1+np.exp(-y_guess))\n",
    "        \n",
    "        return (probs>0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58846900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a21adefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        43\n",
      "           1       0.96      0.94      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.94      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBoostBinaryClassifier(l2_regularization=0,l1_regularization=0,max_depth=50,max_iter=1)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_manual = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(classification_report(y_pred=y_pred_manual,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1db8547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        42\n",
      "           1       0.97      0.96      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "sklearn_XGB = xgb.XGBClassifier()\n",
    "sklearn_XGB.fit(X_train,y_train)\n",
    "y_pred_inbuilt = sklearn_XGB.predict(X_test)\n",
    "print(classification_report(y_pred_inbuilt,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ae4e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_inbuilt == y_pred_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db176e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
